import cv2
import matplotlib.pyplot as plt
from deepface import DeepFace

# Open video capture
video_capture = cv2.VideoCapture(0)  # 0 represents the default camera

# Create a window to display the video
cv2.namedWindow("Real-time Emotion Analysis")

while True:
    # Capture frame-by-frame
    ret, frame = video_capture.read()

    # Perform emotion analysis on the frame
    result = DeepFace.analyze(frame, actions=['emotion'])

    # Retrieve the dominant emotion from the first result in the list
    dominant_emotion = result[0]['dominant_emotion']

    # Display the frame with emotion labels
    cv2.putText(
        frame,
        dominant_emotion,
        (50, 50),
        cv2.FONT_HERSHEY_SIMPLEX,
        1,
        (0, 255, 0),
        2,
        cv2.LINE_AA,
    )

    # Display the frame in a window
    cv2.imshow("Real-time Emotion Analysis", frame)

    # Check for 'q' key press to exit
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close the window
video_capture.release()
cv2.destroyAllWindows()

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c69ebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib>=3.2.2\n",
      "  Using cached matplotlib-3.7.1-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "Collecting numpy<1.24.0,>=1.18.5\n",
      "  Using cached numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Collecting opencv-python>=4.1.1\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Collecting Pillow>=7.1.2\n",
      "  Using cached Pillow-9.5.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Collecting PyYAML>=5.3.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Collecting requests>=2.23.0\n",
      "  Using cached requests-2.30.0-py3-none-any.whl (62 kB)\n",
      "Collecting scipy>=1.4.1\n",
      "  Using cached scipy-1.10.1-cp39-cp39-win_amd64.whl (42.5 MB)\n",
      "Collecting torch!=1.12.0,>=1.7.0\n",
      "  Using cached torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "Collecting torchvision!=0.13.0,>=0.8.1\n",
      "  Using cached torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting protobuf<4.21.3\n",
      "  Using cached protobuf-4.21.2-cp39-cp39-win_amd64.whl (524 kB)\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting pandas>=1.1.4\n",
      "  Using cached pandas-2.0.1-cp39-cp39-win_amd64.whl (10.7 MB)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from -r requirements.txt (line 34)) (8.13.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from -r requirements.txt (line 35)) (5.9.0)\n",
      "Collecting thop\n",
      "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.7-cp39-cp39-win_amd64.whl (160 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.1)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.1.0-cp39-cp39-win_amd64.whl (97 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     -------------------------------------- 61.5/61.5 kB 814.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.5.0)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tqdm>=4.41.0->-r requirements.txt (line 13)) (0.4.6)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (66.0.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.38.4)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Using cached grpcio-1.54.2-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.18.1-py2.py3-none-any.whl (178 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (5.9.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (2.15.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (3.0.38)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (0.18.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (0.6.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.15.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (6.6.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r requirements.txt (line 34)) (0.2.6)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp39-cp39-win_amd64.whl (16 kB)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 34)) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 34)) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 34)) (1.2.0)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: pytz, mpmath, urllib3, tzdata, tqdm, tensorboard-data-server, sympy, PyYAML, pyparsing, pyasn1, protobuf, Pillow, oauthlib, numpy, networkx, MarkupSafe, kiwisolver, importlib-resources, idna, grpcio, fonttools, filelock, cycler, charset-normalizer, certifi, cachetools, absl-py, werkzeug, scipy, rsa, requests, pyasn1-modules, pandas, opencv-python, markdown, jinja2, contourpy, torch, requests-oauthlib, matplotlib, google-auth, torchvision, thop, seaborn, google-auth-oauthlib, tensorboard\n",
      "Successfully installed MarkupSafe-2.1.2 Pillow-9.5.0 PyYAML-6.0 absl-py-1.4.0 cachetools-5.3.0 certifi-2023.5.7 charset-normalizer-3.1.0 contourpy-1.0.7 cycler-0.11.0 filelock-3.12.0 fonttools-4.39.4 google-auth-2.18.1 google-auth-oauthlib-1.0.0 grpcio-1.54.2 idna-3.4 importlib-resources-5.12.0 jinja2-3.1.2 kiwisolver-1.4.4 markdown-3.4.3 matplotlib-3.7.1 mpmath-1.3.0 networkx-3.1 numpy-1.23.5 oauthlib-3.2.2 opencv-python-4.7.0.72 pandas-2.0.1 protobuf-4.21.2 pyasn1-0.5.0 pyasn1-modules-0.3.0 pyparsing-3.0.9 pytz-2023.3 requests-2.30.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.10.1 seaborn-0.12.2 sympy-1.12 tensorboard-2.13.0 tensorboard-data-server-0.7.0 thop-0.1.1.post2209072238 torch-2.0.1 torchvision-0.15.2 tqdm-4.65.0 tzdata-2023.3 urllib3-1.26.15 werkzeug-2.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556578ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\HCI_Project_Phase_2\\yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\dell\\HCI_Project_Phase_2\\yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8244d579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\HCI_Project_Phase_2\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\dell\\HCI_Project_Phase_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e563ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.10.0\n",
      "  Downloading tensorflow_gpu-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "     -------------------------------------- 455.9/455.9 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (1.12.1)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (0.31.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (3.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (66.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (1.4.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (2.10.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (3.19.6)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.5.9-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (3.7.4.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (23.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (1.54.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (16.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow-gpu==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.10.0) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.18.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.30.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (5.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (1.26.15)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (6.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0) (3.2.2)\n",
      "Installing collected packages: flatbuffers, numpy, tensorflow-gpu\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\Users\\\\dell\\\\anaconda3\\\\envs\\\\HCII\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==2.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77ffe831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b7e4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\envs\\hci\\lib\\site-packages (1.23.5)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     -------------------------------------- 14.9/14.9 MB 819.3 kB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "Successfully installed numpy-1.24.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.10.0 requires libclang>=13.0.0, which is not installed.\n",
      "tensorflow 2.10.0 requires tensorflow-io-gcs-filesystem>=0.23.1, which is not installed.\n",
      "tensorflow 2.10.0 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
      "tensorflow 2.10.0 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.24.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af8040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.10.0\n",
      "  Using cached tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow==2.10.0) (1.4.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow==2.10.0) (4.5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow==2.10.0) (1.54.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow==2.10.0) (66.0.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.8.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow==2.10.0) (23.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorflow==2.10.0) (1.23.5)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.5.9-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp39-cp39-win_amd64.whl (36 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.30.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.18.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.15)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (6.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\anaconda3\\envs\\hcii\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, keras, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.0\n",
      "    Uninstalling tensorboard-data-server-0.7.0:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.2\n",
      "    Uninstalling protobuf-4.21.2:\n",
      "      Successfully uninstalled protobuf-4.21.2\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.0.0\n",
      "    Uninstalling google-auth-oauthlib-1.0.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-23.5.9 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 h5py-3.8.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-16.0.0 opt-einsum-3.3.0 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 wrapt-1.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0726d249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.10.0\n",
      "TensorFlow-GPU enabled: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"TensorFlow-GPU enabled:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334775ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1831913709013734969\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4163895296\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4689135538467492096\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b99ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # GPU(s) detected\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU:\", gpu)\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db63dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2b820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "import face_recognition\n",
    "from gaze_tracking import GazeTracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd33926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0069706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98dcd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_filter = ['train'] #You can give list of classes to filter by name ['train','person' ]\n",
    "\n",
    "\n",
    "opt  = {\n",
    "    \"weights\": \"weights/yolov7.pt\", # Path to weights file default weights are for nano model\n",
    "    \"yaml\"   : \"data/coco.yaml\",\n",
    "    \"img-size\": 640, # default image size\n",
    "    \"conf-thres\": 0.25, # confidence threshold for inference.\n",
    "    \"iou-thres\" : 0.45, # NMS IoU threshold for inference.\n",
    "    \"device\" : 'cpu',  # device to run our model i.e. 0 or 0,1,2,3 or cpu\n",
    "    \"classes\" : classes_to_filter  # list of classes to filter or None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Video information\n",
    "# fps = 30  # Adjust the frame rate as needed\n",
    "# w, h = 640, 480  # Set the desired width and height for the video output\n",
    "\n",
    "# # Initializing video object\n",
    "# video = cv2.VideoCapture(0)  # Use index 0 for the default camera\n",
    "\n",
    "# # Initializing object for writing video output\n",
    "# #output = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'DIVX'), fps, (w, h))\n",
    "\n",
    "# # Initializing model and setting it for inference\n",
    "# with torch.no_grad():\n",
    "#     weights = 'weights/yolov7.pt'  # Replace with the path to your YOLOv7 weights\n",
    "#     imgsz = 416  # Set the input image size for the model\n",
    "\n",
    "#     set_logging()\n",
    "#     device = select_device('')\n",
    "#     half = device.type != 'cpu'\n",
    "#     model = attempt_load(weights, map_location=device)\n",
    "#     stride = int(model.stride.max())\n",
    "#     imgsz = check_img_size(imgsz, s=stride)\n",
    "#     if half:\n",
    "#         model.half()\n",
    "\n",
    "#     names = model.module.names if hasattr(model, 'module') else model.names\n",
    "#     colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "#     if device.type != 'cpu':\n",
    "#         model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "#     while True:\n",
    "#         ret, img0 = video.read()\n",
    "\n",
    "#         if ret:\n",
    "#             img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "#             img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "#             img = np.ascontiguousarray(img)\n",
    "#             img = torch.from_numpy(img).to(device)\n",
    "#             img = img.half() if half else img.float()\n",
    "#             img /= 255.0\n",
    "#             if img.ndimension() == 3:\n",
    "#                 img = img.unsqueeze(0)\n",
    "\n",
    "#             # Inference\n",
    "#             t1 = time_synchronized()\n",
    "#             pred = model(img, augment=False)[0]\n",
    "#             pred = non_max_suppression(pred, conf_thres=0.3, iou_thres=0.6)\n",
    "\n",
    "#             t2 = time_synchronized()\n",
    "#             for i, det in enumerate(pred):\n",
    "#                 if len(det):\n",
    "#                     det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "#                     for *xyxy, conf, cls in reversed(det):\n",
    "#                         label = f'{names[int(cls)]} {conf:.2f}'\n",
    "#                         plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "#             cv2.imshow('Object Detection', img0)\n",
    "#             #output.write(cv2.resize(img0, (w, h)))\n",
    "\n",
    "#             if cv2.waitKey(1) == ord('q'):  # Press 'q' to exit\n",
    "#                 break\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "# #output.release()\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4679f38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 306 layers, 36905341 parameters, 36905341 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Looking left\n",
      "Looking left\n",
      "Looking left\n",
      "Looking center\n",
      "Looking right\n",
      "Looking left\n",
      "Looking left\n",
      "Looking left\n",
      "Looking left\n",
      "Looking left\n",
      "Looking left\n",
      "Looking left\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Initialize video capture object\n",
    "# gaze = GazeTracking()\n",
    "# video_capture = cv2.VideoCapture(0)  # Use index 0 for the default camera\n",
    "# # Load a sample picture and learn how to recognize it.\n",
    "# Supra_image = face_recognition.load_image_file(\"Supraa.jpg\")\n",
    "# Supra_face_encoding = face_recognition.face_encodings(Supra_image)[0]\n",
    "# # Load face recognition model and known face encodings\n",
    "# known_face_encodings = [Supra_face_encoding]  # Replace with your known face encodings\n",
    "# known_face_names = ['Supraa']  # Replace with your known face names\n",
    "\n",
    "# # Load object detection model\n",
    "# weights = 'weights/yolov7.pt'  # Replace with the path to your YOLOv7 weights\n",
    "# imgsz = 416  # Set the input image size for the model\n",
    "\n",
    "# set_logging()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# half = device.type != 'cpu'\n",
    "# model = attempt_load(weights, map_location=device)\n",
    "# stride = int(model.stride.max())\n",
    "# imgsz = check_img_size(imgsz, s=stride)\n",
    "# if half:\n",
    "#     model.half()\n",
    "\n",
    "# names = model.module.names if hasattr(model, 'module') else model.names\n",
    "# colors = [[np.random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "# if device.type != 'cpu':\n",
    "#     model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "# # Process frames from the video capture\n",
    "# while True:\n",
    "#     # Grab a single frame of video\n",
    "#     ret, frame = video_capture.read()\n",
    "\n",
    "#     if ret:\n",
    "#         # Face detection\n",
    "#         small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "#         rgb_small_frame = small_frame[:, :, ::-1]\n",
    "#         face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "#         face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "#         gaze.refresh(frame)\n",
    "\n",
    "#         new_frame = gaze.annotated_frame()\n",
    "#         text = \"\"\n",
    "#         if gaze.is_right():\n",
    "#             text = \"Looking right\"\n",
    "#         elif gaze.is_left():\n",
    "#             text = \"Looking left\"\n",
    "#         elif gaze.is_center():\n",
    "#             text = \"Looking center\"\n",
    "#         elif gaze.is_blinking():\n",
    "#             text = \"Blinking\"\n",
    "            \n",
    "#         cv2.putText(new_frame, text, (60, 60), cv2.FONT_HERSHEY_DUPLEX, 2, (255, 0, 0), 2)\n",
    "#         print(text)\n",
    "#         face_names = []\n",
    "#         for face_encoding in face_encodings:\n",
    "#             matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "#             name = \"Unknown\"\n",
    "\n",
    "#             face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "#             best_match_index = np.argmin(face_distances)\n",
    "#             if matches[best_match_index]:\n",
    "#                 name = known_face_names[best_match_index]\n",
    "\n",
    "#             face_names.append(name)\n",
    "\n",
    "#         # Object detection\n",
    "#         img0 = frame\n",
    "#         img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "#         img = img[:, :, ::-1].transpose(2, 0, 1)\n",
    "#         img = np.ascontiguousarray(img)\n",
    "#         img = torch.from_numpy(img).to(device)\n",
    "#         img = img.half() if half else img.float()\n",
    "#         img /= 255.0\n",
    "#         if img.ndimension() == 3:\n",
    "#             img = img.unsqueeze(0)\n",
    "\n",
    "#         # Inference\n",
    "#         t1 = time_synchronized()\n",
    "#         pred = model(img, augment=False)[0]\n",
    "#         pred = non_max_suppression(pred, conf_thres=0.3, iou_thres=0.6)\n",
    "#         t2 = time_synchronized()\n",
    "\n",
    "#         # Display the results\n",
    "#         for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "#             top *= 4\n",
    "#             right *= 4\n",
    "#             bottom *= 4\n",
    "#             left *= 4\n",
    "\n",
    "#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "#             cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "#             font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#             cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "#         for i, det in enumerate(pred):\n",
    "#             if len(det):\n",
    "#                 det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "#                 for *xyxy, conf, cls in reversed(det):\n",
    "#                     label = f'{names[int(cls)]} {conf:.2f}'\n",
    "#                     plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "#         cv2.imshow('Video', frame)\n",
    "#         if cv2.waitKey(1) == ord('q'):  # Press 'q' to exit\n",
    "#             break\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# # Release resources\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3797b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  2023-5-20 torch 2.0.1+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 306 layers, 36905341 parameters, 36905341 gradients\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize video capture object\n",
    "video_capture = cv2.VideoCapture(0)  # Use index 0 for the default camera\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "Supra_image = face_recognition.load_image_file(\"Supraa.jpg\")\n",
    "Supra_face_encoding = face_recognition.face_encodings(Supra_image)[0]\n",
    "# Load face recognition model and known face encodings\n",
    "known_face_encodings = [Supra_face_encoding]  # Replace with your known face encodings\n",
    "known_face_names = ['Supraa']  # Replace with your known face names\n",
    "\n",
    "# Load object detection model\n",
    "weights = 'weights/yolov7.pt'  # Replace with the path to your YOLOv7 weights\n",
    "imgsz = 416  # Set the input image size for the model\n",
    "\n",
    "set_logging()\n",
    "device = select_device('')\n",
    "half = device.type != 'cpu'\n",
    "model = attempt_load(weights, map_location=device)\n",
    "stride = int(model.stride.max())\n",
    "imgsz = check_img_size(imgsz, s=stride)\n",
    "if half:\n",
    "    model.half()\n",
    "\n",
    "names = model.module.names if hasattr(model, 'module') else model.names\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "# Process frames from the video capture\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if ret:\n",
    "        # Face detection\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "        # Object detection\n",
    "        img0 = frame\n",
    "        img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()\n",
    "        img /= 255.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=False)[0]\n",
    "        pred = non_max_suppression(pred, conf_thres=0.3, iou_thres=0.6)\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Display the results\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        for i, det in enumerate(pred):\n",
    "            if len(det):\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    label = f'{names[int(cls)]} {conf:.2f}'\n",
    "                    plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d73122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
